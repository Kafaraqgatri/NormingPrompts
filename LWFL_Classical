import os
import time
import re
import statistics
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

# --------------------------------------------------------------------------
# 0.  Config & client
# --------------------------------------------------------------------------
load_dotenv(r"C:\Users\Cagi\API.env")
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
MODEL_NAME = "gpt-4o"

# --------------------------------------------------------------------------
# 1.  Iteration setting
# --------------------------------------------------------------------------
N_ITER = 10   # number of times to sample each metaphor

# --------------------------------------------------------------------------
# 2.  Prompt templates (classic psycholinguistic aptness with anchors)
# --------------------------------------------------------------------------
SYSTEM_MSG = (
    "You are a native English speaker rating metaphors in a classic psycholinguistic task.\n"
    "Aptness = the extent to which properties of the vehicle capture important features of the topic.\n\n"
    "“silky hair” is highly apt because silky matches the hair’s shiny, smooth properties — rating ≈ 6–7.\n"
    "“silky sunset” is much less apt; sunsets are rarely both shiny and smooth — rating ≈ 3–4.\n\n"
    "Use a 7-point scale (1 = not apt at all, 7 = extremely apt).\n"
    "Return your answer in exactly this format (nothing else):\n"
    "Rating: <1-7>\n"
    "Reason: <one concise sentence>"
)

USER_TEMPLATE = (
    "Metaphor: \"{met}\"\n\n"
    "Number only, then one-sentence justification:"
)

def make_user_msg(metaphor: str) -> str:
    return USER_TEMPLATE.format(met=metaphor)

# --------------------------------------------------------------------------
# 3.  Helper: get one rating
# --------------------------------------------------------------------------
def rate_once(metaphor: str, retries: int = 3) -> int | None:
    for _ in range(retries):
        try:
            resp = client.chat.completions.create(
                model=MODEL_NAME,
                temperature=0,   # deterministic; raise for variability
                max_tokens=60,
                messages=[
                    {"role": "system", "content": SYSTEM_MSG},
                    {"role": "user",   "content": make_user_msg(metaphor)},
                ],
            )
            text = resp.choices[0].message.content.strip()
            m = re.match(r".*?([1-7])", text)  # grab first digit 1–7
            if m:
                return int(m.group(1))
        except Exception as e:
            print("⚠️ retrying after error:", e)
            time.sleep(1)
    return None

# --------------------------------------------------------------------------
# 4.  Load Excel sheet & collect averaged ratings + SD
# --------------------------------------------------------------------------
excel_path = r"C:\Users\Cagi\Desktop\LWfl\Stimuli\Pavia Learning Study - WordList.xlsx"
df = pd.read_excel(excel_path, sheet_name="GPT", usecols=["MET"])

means, std_devs = [], []

for idx, row in df.iterrows():
    met = row["MET"]
    samples = []
    for _ in range(N_ITER):
        s = rate_once(met)
        if s is not None:
            samples.append(s)
        time.sleep(0.3)
    if samples:
        means.append(statistics.mean(samples))
        std_devs.append(statistics.stdev(samples))
    else:
        means.append(None)
        std_devs.append(None)
    print(f"{idx+1:3d}. {met[:50]:50s} → mean={means[-1]:.2f}, sd={std_devs[-1]:.2f}")

# --------------------------------------------------------------------------
# 5.  Save results
# --------------------------------------------------------------------------
df["MEAN_RATING"] = means
df["SD_RATING"]   = std_devs

out_path = r"C:\Users\Cagi\Desktop\LWfl\Stimuli\PaviaLearning_final_general.xlsx"
df.to_excel(out_path, index=False)
print(f"\nAll done! Ratings saved to:\n  {out_path}")
